#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
from pathlib import Path
from typing import List

from PIL import Image
from ultralytics import YOLO
from sahi import AutoDetectionModel
from sahi.slicing import slice_image

import random
import shutil
from collections import defaultdict

#from sahi.predict import get_sliced_prediction, save_sliced_prediction_json
#from sahi.predict import get_sliced_prediction
#from sahi.utils.file import export_visualizations
#from sahi.utils.file import export_visualizations
#from sahi.utils.file import export_visualizations
import sahi # sahi íŒ¨í‚¤ì§€ ì „ì²´ë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤.

# =======================
# ê²½ë¡œ / ì„¤ì •
# =======================
DATA_ROOT = Path("/home/dongbae/Dev/WheelScan/data/original_data")
TRAIN_IMAGES = DATA_ROOT / "train/images"
VAL_IMAGES   = DATA_ROOT / "valid/images"
TEST_IMAGES  = DATA_ROOT / "test/images"

MODELS_ROOT = Path("/home/dongbae/Dev/WheelScan/models/")
STAGE1_DIR = MODELS_ROOT / "step1"
STAGE2_DIR = MODELS_ROOT / "step2"
STAGE3_DIR = MODELS_ROOT / "step3"
STAGE4_DIR = MODELS_ROOT / "step4"

DATA_YAML = Path("/home/dongbae/Dev/WheelScan/data/original_data/data.yaml")
MODEL_CFG = Path("/home/dongbae/Dev/WheelScan/yolo11m-p2.yaml")

TRAIN_CFG = dict(
    imgsz=640,
    epochs=300,
    batch=6,
    workers=4,
    seed=42,
    patience=30,

    box=0.08,
    cls=0.20,
    dfl=1.5,

    mosaic=0.90,
    copy_paste=0.40,
    mixup=0.1,
    erasing=0.10,
    close_mosaic=10,

    degrees=5.0,
    shear=0.0,
    perspective=0.0,
    translate=0.05,
    scale=0.60,
    hsv_h=0.015, hsv_s=0.50, hsv_v=0.40,
    fliplr=0.5, flipud=0.0,

    rect=True,
    optimizer="AdamW",
    lr0=0.003,
    lrf=0.20,
    weight_decay=0.0005,
    freeze=0,
    amp=True,
    cache=True,
    verbose=False,
    plots=True,
)

# (ì´ë¯¸ ì¤€ë¹„ëœ) íœ -í¬ë¡­ ë°ì´í„°ì…‹
CROP_TRAIN = Path("/home/dongbae/Dev/WheelScan/data/train_tiles")
CROP_VAL   = Path("/home/dongbae/Dev/WheelScan/data/valid_tiles")
CROP_TEST  = Path("/home/dongbae/Dev/WheelScan/data/test_tiles")

# íƒ€ì¼ë§ ê²°ê³¼ ì €ì¥ ë£¨íŠ¸
TILE_ROOT  = Path("/home/dongbae/Dev/WheelScan/data/tiles_out")
FINAL_ROOT = Path("/home/dongbae/Dev/WheelScan/data/final_splits")
TILE_TRAIN = TILE_ROOT / "train"
TILE_VAL   = TILE_ROOT / "valid"
TILE_TEST  = TILE_ROOT / "test"

# íƒ€ì¼ í•™ìŠµìš© data.yaml (ìˆ˜ë™ ìƒì„±)
DATA_YAML_TILES = FINAL_ROOT / "data_tiles.yaml"

# ====== SAHI ì„¤ì • (ìŠ¤ìœ„ì¹˜ ê°€ëŠ¥) ======
SAHI_CFG = dict(
    # --- ë¶„í•  ë°©ì‹ ---
    # "size"   : ê³ ì • í¬ê¸° íƒ€ì¼ (SPLIT_VALUE=íƒ€ì¼ ë³€ px)
    # "count_v": ì„¸ë¡œ Në“±ë¶„ (SPLIT_VALUE=N)
    SPLIT_FLAG="count_v",
    SPLIT_VALUE=6,

    # --- ê²¹ì¹¨ ë¹„ìœ¨ ---
    overlap_h=0.10,   # ì„¸ë¡œ ê²¹ì¹¨
    overlap_w=0.00,   # ê°€ë¡œ ê²¹ì¹¨ (count_v ëª¨ë“œë©´ ë³´í†µ 0.0 ê¶Œì¥)

    # --- ì¶”ë¡ /í›„ì²˜ë¦¬ ---
    conf_thres=0.8,
    postprocess="NMS",
    match_metric="IOU",
    match_thres=0.45
)


# =======================
# ìœ í‹¸
# =======================
def ensure_dir(p: Path):
    p.mkdir(parents=True, exist_ok=True)

def list_images(dir_path: Path) -> List[Path]:
    exts = ("*.jpg", "*.jpeg", "*.png", "*.bmp", "*.tif", "*.tiff")
    files: List[Path] = []
    for e in exts:
        files.extend(dir_path.glob(e))
    return sorted(files)

def device_str() -> str:
    try:
        import torch
        return "cuda:0" if torch.cuda.is_available() else "cpu"
    except Exception:
        return "cpu"

def compute_slice_params(W: int, H: int, cfg: dict):
    """SPLIT_FLAG/SPLIT_VALUEì— ë”°ë¼ slice_height/widthì™€ overlap ë¹„ìœ¨ì„ ê³„ì‚°"""
    flag = cfg.get("SPLIT_FLAG", "size")
    val  = int(cfg.get("SPLIT_VALUE", 640))
    ovh  = float(cfg.get("overlap_h", 0.25))
    ovw  = float(cfg.get("overlap_w", 0.25))

    if flag == "count_v":  # ì„¸ë¡œ ë“±ë¶„
        slice_h = max(1, H // max(1, val))
        slice_w = W
        return slice_h, slice_w, ovh, 0.0
    else:                  # "size": ì •ì‚¬ê° íƒ€ì¼
        slice_h = val
        slice_w = val
        return slice_h, slice_w, ovh, ovw


# =======================
# [1ë‹¨ê³„] (ì˜µì…˜) ì›ë³¸ í•™ìŠµ
# =======================
def stage1_train_p2(data_yaml: Path, out_dir: Path) -> Path:
    print("\n=== [1ë‹¨ê³„] í•™ìŠµ ì‹œì‘ (yolo11m-p2) ===")
    print(f"data: {data_yaml}")
    print(f"model cfg: {MODEL_CFG}")

    model = YOLO(MODEL_CFG)
    train_args = {
        "data": str(data_yaml),
        "project": str(MODELS_ROOT),
        "name": out_dir.name,
        "device": device_str(),
        **TRAIN_CFG,
        "exist_ok": True,
    }
    results = model.train(**train_args)
    best = Path(results.save_dir) / "weights" / "best.pt"
    print(f"[1ë‹¨ê³„ ì™„ë£Œ] best weights: {best}")
    return best


# =======================
# [2ë‹¨ê³„] SAHI íƒ€ì¼ ë¶„í•  (size/count_v ìŠ¤ìœ„ì¹˜)
# =======================
from pathlib import Path
from PIL import Image
# compute_slice_params, slice_image, CROP_TRAIN, CROP_VAL, CROP_TEST, TILE_ROOT, SAHI_CFG ë“±ì€ 
# ì™¸ë¶€ì—ì„œ ì •ì˜ëœ ê²ƒìœ¼ë¡œ ê°€ì •í•˜ê³  ì½”ë“œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

def stage2_tile_all_with_sahi(
    keep_empty: bool = True,
    min_side_px: int = 2,
    min_intersection_ratio: float = 0.2,
):
    """
    CROP_TRAIN/CROP_VAL/CROP_TEST (images/labels)ì˜ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ íƒ€ì¼ ë¶„í• í•˜ì—¬
    ë‹¨ì¼ í´ë” (TILE_ROOT)ì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    
    # TILE_ROOTê°€ /home/dongbae/Dev/WheelScan/data/tiles_out ê²½ë¡œë¼ê³  ê°€ì •
    # ì´ í´ë” ì•„ë˜ imagesì™€ labelsë¥¼ ë§Œë“¤ê³  ëª¨ë“  íƒ€ì¼ ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
    dst_img_root = TILE_ROOT / "images"
    dst_lbl_root = TILE_ROOT / "labels"
    dst_img_root.mkdir(parents=True, exist_ok=True)
    dst_lbl_root.mkdir(parents=True, exist_ok=True)

    def tile_one_split(src_split: Path):
        """
        íŠ¹ì • ë¶„í• (src_split)ì˜ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì™€ TILE_ROOTì— íƒ€ì¼ë§ ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
        """
        src_img = src_split / "images"
        src_lbl = src_split / "labels"

        exts = (".jpg",".jpeg",".png",".bmp",".tif",".tiff")
        for ip in sorted(src_img.iterdir()):
            if ip.suffix.lower() not in exts:
                continue

            im = Image.open(ip).convert("RGB")
            W, H = im.size
            
            # SAHI íŒŒë¼ë¯¸í„° ê³„ì‚°ì€ í•œ ë²ˆë§Œ ìˆ˜í–‰
            # ì´ íŒŒë¼ë¯¸í„°ëŠ” SAHI_CFGì— ë”°ë¼ ì •í•´ì§€ë©°, ëª¨ë“  ì´ë¯¸ì§€ì— ë™ì¼í•˜ê²Œ ì ìš©ë©ë‹ˆë‹¤.
            slice_h, slice_w, ovh, ovw = compute_slice_params(W, H, SAHI_CFG) 

            sliced_list = slice_image(
                image=im,
                slice_height=slice_h,
                slice_width=slice_w,
                overlap_height_ratio=ovh,
                overlap_width_ratio=ovw
            )

            # ì›ë³¸ YOLO ë¼ë²¨(px ì¢Œí‘œë¡œ ë³€í™˜)
            ypath = src_lbl / (ip.stem + ".txt")
            boxes = []
            if ypath.exists():
                with open(ypath, "r") as f:
                    for line in f:
                        line = line.strip()
                        if not line:
                            continue
                        parts = line.split()
                        cls = int(parts[0])
                        cx, cy, ww, hh = map(float, parts[1:5])
                        bx = cx*W; by = cy*H; bw = ww*W; bh = hh*H
                        x1 = bx - bw/2; y1 = by - bh/2
                        x2 = bx + bw/2; y2 = by + bh/2
                        boxes.append((cls, x1,y1,x2,y2, bw*bh))  # (cls, x1,y1,x2,y2, area)

            # ê° ìŠ¬ë¼ì´ìŠ¤ ì €ì¥ + ë¼ë²¨ í´ë¦¬í•‘/ì •ê·œí™”
            for si in sliced_list:
                
                # --- SAHI ì¢Œí‘œ ì¶”ì¶œ ë° í¬ê¸° ê³„ì‚° (ì´ì „ ìˆ˜ì • ë°˜ì˜) ---
                x0, y0 = si["starting_pixel"]
                # tw_slice, th_slice = si["image"].size ë¡œ ì¸í•œ ì—ëŸ¬ ëŒ€ì‹  slice_w, slice_h ì‚¬ìš©
                tw_slice, th_slice = slice_w, slice_h 

                x1t, y1t = x0 + tw_slice, y0 + th_slice
                
                # ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ íƒ€ì¼ ìë¥´ê¸°
                crop = im.crop((x0, y0, x1t, y1t))
                tw, th = crop.size # íƒ€ì¼ì˜ ì‹¤ì œ í¬ê¸° (tw, th)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ê·œí™”
                # ------------------------------------------------

                new_lines = []
                for (cls, x1,y1,x2,y2, area) in boxes:
                    ix1 = max(x1, x0); iy1 = max(y1, y0)
                    ix2 = min(x2, x1t); iy2 = min(y2, y1t)
                    iw = ix2 - ix1; ih = iy2 - iy1
                    if iw <= 0 or ih <= 0:
                        continue
                    if iw < min_side_px or ih < min_side_px:
                        continue
                    if (iw*ih) / (area + 1e-6) < min_intersection_ratio:
                        continue

                    cx_t = ((ix1 + ix2)/2 - x0) / tw
                    cy_t = ((iy1 + iy2)/2 - y0) / th
                    w_t  = iw / tw
                    w_t = min(max(w_t, 1e-6), 1.0) # 0 ë˜ëŠ” 1.0 ì´ˆê³¼ ë°©ì§€
                    h_t  = ih / th
                    h_t = min(max(h_t, 1e-6), 1.0) # 0 ë˜ëŠ” 1.0 ì´ˆê³¼ ë°©ì§€


                    if w_t <= 0 or h_t <= 0:
                        continue
                    cx_t = min(max(cx_t, 0.0), 1.0)
                    cy_t = min(max(cy_t, 0.0), 1.0)

                    new_lines.append(f"{cls} {cx_t:.6f} {cy_t:.6f} {w_t:.6f} {h_t:.6f}")

                # íƒ€ì¼ ì´ë¦„ì„ 'ì›ë³¸ì´ë¯¸ì§€ëª…_xì‹œì‘ì¢Œí‘œ_yì‹œì‘ì¢Œí‘œ'ë¡œ í†µì¼í•˜ì—¬ ë‹¨ì¼ í´ë”ì— ì €ì¥
                tile_name = f"{ip.stem}_{x0}_{y0}"
                crop.save(dst_img_root / f"{tile_name}.jpg", quality=95)
                with open(dst_lbl_root / f"{tile_name}.txt", "w") as f:
                    if new_lines or keep_empty:
                        f.write("\n".join(new_lines))

    print("\n=== [2ë‹¨ê³„] SAHI íƒ€ì¼ ë¶„í•  ì‹œì‘ (ë‹¨ì¼ ì¶œë ¥ ëª¨ë“œ) ===")
    
    # TILE_ROOT í´ë”ì— ëª¨ë“  ê²°ê³¼ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•´ train, val, testë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬
    tile_one_split(CROP_TRAIN)
    tile_one_split(CROP_VAL)
    tile_one_split(CROP_TEST)
    
    print(f"[2ë‹¨ê³„ ì™„ë£Œ] íƒ€ì¼ ë°ì´í„°ì…‹ root: {TILE_ROOT}")
    print(f" - ì¶œë ¥ í´ë”: {dst_img_root.parent}")
    print(f" - ëª¨ë“œ: {SAHI_CFG['SPLIT_FLAG']}, ê°’: {SAHI_CFG['SPLIT_VALUE']}")
    print(f" - overlap_h: {SAHI_CFG['overlap_h']}, overlap_w: {SAHI_CFG['overlap_w']}")


#===============================
# 2.5ë‹¨ê³„ : ë°ì´í„° ì˜¤ë²„ìƒ˜í”Œë§
#===============================

def create_iterative_splits(tile_root: Path, num_iterations: int = 8, train_ratio: float = 0.8):
    
    label_dir = tile_root / "labels"
    image_dir = tile_root / "images"
    
    # ìµœì¢… ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    final_output_root = tile_root.parent / "final_splits"

    # ì´ì „ ê²°ê³¼ ì‚­ì œ ë° ìƒˆ í´ë” ìƒì„±
    if final_output_root.exists():
        shutil.rmtree(final_output_root)
    
    # 1. ëª¨ë“  ë¼ë²¨ íŒŒì¼ ë¶„ë¥˜ (ì´ì „ê³¼ ë™ì¼)
    all_label_files = list(label_dir.glob("*.txt"))
    
    class_0_files = [] 
    class_1_files = [] 
    empty_files = []   

    for label_path in all_label_files:
        content = label_path.read_text().strip()
        if not content:
            empty_files.append(label_path)
            continue
        
        classes = {int(line.split()[0]) for line in content.split('\n') if line}
        has_class_1 = 1 in classes
        has_class_0 = 0 in classes

        if has_class_1:
             class_1_files.append(label_path)
        elif has_class_0:
            class_0_files.append(label_path)
        else:
            class_0_files.append(label_path) 
    
    # 2. ë°˜ë³µ ì¶”ì¶œì„ ìœ„í•œ ë³€ìˆ˜ ì´ˆê¸°í™”
    # ìµœì¢…ì ìœ¼ë¡œ ë³µì œë  íŒŒì¼ì˜ ëª©ë¡. (original_path, new_name_stem) íŠœí”Œ ì €ì¥
    final_replicated_list = [] 
    
    # ì •ìƒ íŒŒì¼ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë³€ìˆ˜ ì´ˆê¸°í™” (ë¹„ë³µì› ì¶”ì¶œ, 1/8ì”©)
    random.shuffle(empty_files)
    num_empty_files = len(empty_files)
    empty_split_size = num_empty_files // num_iterations 
    empty_current_index = 0
    
    # ê²°í•¨ 1ë²ˆ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë³€ìˆ˜ ì´ˆê¸°í™” (í˜¼í•© ì¶”ì¶œ)
    num_class_1 = len(class_1_files)
    class_1_total_to_extract = num_class_1 // 2 
    class_1_extract_cycle_count = num_iterations // 2 # ì´ 4ë²ˆì˜ ì‚¬ì´í´
    
    class_1_files_for_loop = list(class_1_files)
    class_1_current_index = 0
    
    
    # 3. 8ë²ˆ ë°˜ë³µí•˜ë©´ì„œ ë³µì œ ë¦¬ìŠ¤íŠ¸ êµ¬ì„±
    for i in range(num_iterations):
        
        # 3-1. ê²°í•¨ 0ë²ˆ íŒŒì¼ (ëª¨ë“  ë°˜ë³µë§ˆë‹¤ ë³µì œ: ì´ 8ë²ˆ ë³µì œ)
        for label_path in class_0_files:
            new_name = f"{label_path.stem}_{i}"
            final_replicated_list.append((label_path, new_name))
        
        # 3-2. ê²°í•¨ 1ë²ˆ íŒŒì¼ (2ë£¨í”„ë§ˆë‹¤ 1/2ì”© ë¹„ë³µì› ì¶”ì¶œ, ì´ 4ë²ˆ ë³µì œ)
        
        # ìƒˆë¡œìš´ 4ì‚¬ì´í´ì˜ ì‹œì‘ (i=0, 2, 4, 6)
        if i % 2 == 0: 
            # 1. ì „ì²´ íŒŒì¼ ì…”í”Œ (ë³µì› ì¶”ì¶œ íš¨ê³¼)
            random.shuffle(class_1_files_for_loop)
            # 2. ì¸ë±ìŠ¤ ë¦¬ì…‹ (ë¹„ë³µì› ì¶”ì¶œ ì‹œì‘)
            class_1_current_index = 0
            
            # 2ë²ˆì˜ ë£¨í”„ì— ê±¸ì³ ì¶”ì¶œë  ì–‘ (1/2)ì„ 2ë¡œ ë‚˜ëˆ” (1/4)
            class_1_split_size = class_1_total_to_extract // 2
            
        # ì¶”ì¶œ ì‹¤í–‰
        if class_1_current_index < num_class_1: 
            start_index = class_1_current_index
            
            # ì§ìˆ˜ ë£¨í”„(i=0, 2, 4, 6)ì—ì„œëŠ” 1/4 ì¶”ì¶œ
            if i % 2 == 0: 
                end_index = min(start_index + class_1_split_size, num_class_1)
            # í™€ìˆ˜ ë£¨í”„(i=1, 3, 5, 7)ì—ì„œëŠ” ë‚˜ë¨¸ì§€ 1/4 ì¶”ì¶œ
            else: 
                # ë‚¨ì€ 1/2 ì¤‘ ë‚˜ë¨¸ì§€ë¥¼ ëª¨ë‘ ì¶”ì¶œ
                end_index = start_index + (class_1_total_to_extract - class_1_split_size)
                end_index = min(end_index, num_class_1) 
                
            selected_class_1 = class_1_files_for_loop[start_index:end_index]
            
            # ì¶”ì¶œëœ íŒŒì¼ì€ ë³µì œë©ë‹ˆë‹¤. (ì´ 4ë²ˆ ë³µì œ ë¡œì§)
            # ë³µì œ ì¸ë±ìŠ¤: 0, 0, 1, 1, 2, 2, 3, 3 -> i // 2 ì‚¬ìš©
            replicate_idx = i // 2
            for label_path in selected_class_1:
                new_name = f"{label_path.stem}_{replicate_idx}"
                final_replicated_list.append((label_path, new_name))
                
            class_1_current_index = end_index # ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ (ë¹„ë³µì›)
            
        # 3-3. ë¹ˆ íŒŒì¼ (ì •ìƒ) (1/8 ë¹„ë³µì› ì¶”ì¶œ: 1ë²ˆë§Œ ì¶”ê°€)
        start_index = empty_current_index
        end_index = min(empty_current_index + empty_split_size, num_empty_files)
        
        if i == num_iterations - 1:
            end_index = num_empty_files
            
        selected_empty = empty_files[start_index:end_index]
        
        # ë¹ˆ íŒŒì¼ì€ ë³µì œí•˜ì§€ ì•Šê³ , ì›ë³¸ íŒŒì¼ëª… ê·¸ëŒ€ë¡œ final_replicated_listì— ì¶”ê°€
        for label_path in selected_empty:
            final_replicated_list.append((label_path, label_path.stem))
            
        empty_current_index = end_index

    # 4. ìµœì¢… ë°ì´í„°ì…‹ ë¶„í•  (8:2)
    # final_replicated_list: ë³µì œë˜ì–´ ì¤‘ë³µëœ íŒŒì¼(Path, name)ì˜ ì´ ëª©ë¡
    random.shuffle(final_replicated_list)
    
    num_total = len(final_replicated_list)
    num_train = int(num_total * train_ratio)
    
    train_replicated = final_replicated_list[:num_train]
    valid_replicated = final_replicated_list[num_train:]

    print(f"\n--- ìµœì¢… Train/Valid ë¶„í•  (ì´ {num_total}ê°œ íŒŒì¼) ---")
    print(f"Train ì…‹ (ë³µì œ): {len(train_replicated)}ê°œ íŒŒì¼ ({train_ratio*100:.0f}%)")
    print(f"Valid ì…‹ (ë³µì œ): {len(valid_replicated)}ê°œ íŒŒì¼ ({(1-train_ratio)*100:.0f}%)")

    # 5. íŒŒì¼ ë³µì‚¬ ë° ë°ì´í„°ì…‹ ìƒì„±
    train_output_dir = final_output_root / "train"
    valid_output_dir = final_output_root / "valid"
    (train_output_dir / "images").mkdir(parents=True)
    (train_output_dir / "labels").mkdir(parents=True)
    (valid_output_dir / "images").mkdir(parents=True)
    (valid_output_dir / "labels").mkdir(parents=True)
    
    def replicate_and_copy(replicated_list, target_dir):
        """ì›ë³¸ íŒŒì¼ì„ ì½ì–´ì™€ ìƒˆë¡œìš´ ì´ë¦„ìœ¼ë¡œ ì´ë¯¸ì§€ì™€ ë¼ë²¨ì„ ë³µì œ ë° ì €ì¥í•©ë‹ˆë‹¤."""
        target_img_dir = target_dir / "images"
        target_lbl_dir = target_dir / "labels"
        
        for original_path, new_stem in replicated_list:
            original_stem = original_path.stem
            
            # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ (ëª¨ë“  íƒ€ì¼ ì´ë¯¸ì§€ë¥¼ .jpgë¡œ ê°€ì •)
            original_image_path = image_dir / f"{original_stem}.jpg"
            
            if original_image_path.exists() and original_path.exists():
                # ìƒˆ íŒŒì¼ëª…
                new_image_name = f"{new_stem}.jpg"
                new_label_name = f"{new_stem}.txt"
                
                # ë³µì œ ë° ì €ì¥
                shutil.copy(original_image_path, target_img_dir / new_image_name)
                shutil.copy(original_path, target_lbl_dir / new_label_name)
                
    replicate_and_copy(train_replicated, train_output_dir)
    replicate_and_copy(valid_replicated, valid_output_dir)

    print(f"\nâœ… ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ! ì¶œë ¥ ê²½ë¡œ: {final_output_root}")
    print(f"   - Train/Valid images/labelsì— ë³µì œ íŒŒì¼ ì €ì¥ ì™„ë£Œ")

    return final_output_root


# =======================
# [2.6ë‹¨ê³„] ì˜¤ë²„ìƒ˜í”Œë§ - ê²°í•¨ë°ì´í„°ë§Œ
# =======================

# ì „ì—­ ê²½ë¡œ ì„¤ì •ì„ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì‚¬ìš©í•œë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
from typing import List, Tuple
def oversample_tiles_for_2_loops(tile_root: Path, train_ratio: float = 0.8) -> Path:
    """
    íƒ€ì¼ ë°ì´í„°ì…‹(TILE_ROOT)ì—ì„œ ê²°í•¨ ë°ì´í„°ë¥¼ 2ë²ˆì˜ ë£¨í”„ë¥¼ í†µí•´ ì˜¤ë²„ìƒ˜í”Œë§í•˜ê³ ,
    ìµœì¢…ì ìœ¼ë¡œ í›ˆë ¨/ê²€ì¦(Train/Valid) ì„¸íŠ¸ë¡œ ë¶„í• í•˜ì—¬ FINAL_ROOTì— ì €ì¥í•©ë‹ˆë‹¤.
    (ì£¼ì˜: ë¼ë²¨ì´ ë¹„ì–´ìˆëŠ” íŒŒì¼ì€ ìµœì¢… ë°ì´í„°ì…‹ì—ì„œ ì™„ì „íˆ ì œì™¸ë©ë‹ˆë‹¤.)

    Args:
        tile_root: íƒ€ì¼ ì´ë¯¸ì§€ì™€ ë¼ë²¨ì´ ì €ì¥ëœ ë£¨íŠ¸ ê²½ë¡œ (ì˜ˆ: /data/tiles_out)
        final_root: ìµœì¢… ë¶„í•  ë°ì´í„°ë¥¼ ì €ì¥í•  ê²½ë¡œ (ì˜ˆ: /data/final_splits)
        train_ratio: í›ˆë ¨ ì„¸íŠ¸ ë¹„ìœ¨ (ê¸°ë³¸ 0.8)

    Returns:
        ìµœì¢… ë°ì´í„°ì…‹ì´ ì €ì¥ëœ ê²½ë¡œ (Path)
    """
    label_dir = tile_root / "labels"
    image_dir = tile_root / "images"
    num_loops = 2

    final_root = tile_root.parent / "final_splits"

    # 1. ì´ì „ ê²°ê³¼ ì‚­ì œ ë° ìƒˆ í´ë” ìƒì„±
    if final_root.exists():
        shutil.rmtree(final_root)

    # 2. ëª¨ë“  ë¼ë²¨ íŒŒì¼ ë¶„ë¥˜
    all_label_files: List[Path] = list(label_dir.glob("*.txt"))

    class_0_files: List[Path] = []  # ê²°í•¨0 (ë³µì œ ëŒ€ìƒ)
    class_1_files: List[Path] = []  # ê²°í•¨1 (ë‚˜ëˆ ì„œ ì¶”ì¶œ ëŒ€ìƒ)
    # empty_filesëŠ” ì œì™¸í•˜ë¯€ë¡œ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

    for label_path in all_label_files:
        content = label_path.read_text().strip()
        if not content:
            # â­ ë¼ë²¨ì´ ë¹„ì–´ìˆëŠ” íŒŒì¼(ì •ìƒ/ë°°ê²½)ì€ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•˜ì§€ ì•Šê³  ê±´ë„ˆëœë‹ˆë‹¤.
            continue 

        classes = {int(line.split()[0]) for line in content.split('\n') if line}
        has_class_1 = 1 in classes
        has_class_0 = 0 in classes

        if has_class_1:
            class_1_files.append(label_path)
        elif has_class_0:
            class_0_files.append(label_path)
        
        # class 0, 1 ì™¸ì˜ í´ë˜ìŠ¤ëŠ” ë¬´ì‹œí•˜ê±°ë‚˜, í•„ìš”ì— ë”°ë¼ ì²˜ë¦¬ ë¡œì§ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    # 3. ë£¨í”„ë¥¼ ëŒë©° ë³µì œ ë¦¬ìŠ¤íŠ¸ êµ¬ì„±
    final_replicated_list: List[Tuple[Path, str]] = []  # (original_path, new_name_stem)

    # ê²°í•¨1 ë°ì´í„°ë¥¼ ì ˆë°˜ì”© ë‚˜ëˆ„ê¸° ìœ„í•´ ì„ìŠµë‹ˆë‹¤.
    random.shuffle(class_1_files)
    num_class_1 = len(class_1_files)
    half_class_1 = num_class_1 // 2
    
    for i in range(num_loops):
        print(f"--- ì˜¤ë²„ìƒ˜í”Œë§ ë£¨í”„ {i+1}/{num_loops} ---")
        
        # 3-1. ê·¸ë£¹0 (ê²°í•¨0) íŒŒì¼ ë³µì œ/ì¶”ì¶œ (ëª¨ë“  ë£¨í”„ì—ì„œ ë³µì œ)
        for label_path in class_0_files:
            # ë³µì œ íŒŒì¼ì„ ì›ë³¸ê³¼ êµ¬ë³„í•˜ê¸° ìœ„í•´ ë£¨í”„ ì¸ë±ìŠ¤(i)ë¥¼ íŒŒì¼ëª…ì— ì¶”ê°€
            new_name = f"{label_path.stem}_d0_{i+1}" 
            final_replicated_list.append((label_path, new_name))
        
        # 3-2. ê·¸ë£¹1 (ê²°í•¨1) íŒŒì¼ ì ˆë°˜ ì¶”ì¶œ (ë¹„ë³µì› ì¶”ì¶œ)
        if i == 0:
            selected_class_1 = class_1_files[:half_class_1]
        else: # i == 1
            selected_class_1 = class_1_files[half_class_1:]

        # ê²°í•¨1 íŒŒì¼ì€ ë£¨í”„ ì¸ë±ìŠ¤ë¥¼ ë¶™ì—¬ ìµœì¢… ë°ì´í„°ì…‹ì— ì„œë¡œ ë‹¤ë¥¸ íŒŒì¼ë¡œ ì¡´ì¬í•˜ê²Œ í•©ë‹ˆë‹¤.
        for label_path in selected_class_1:
            new_name = f"{label_path.stem}_d1_{i+1}"
            final_replicated_list.append((label_path, new_name))
            
        # âŒ 3-3. ì •ìƒ(ë°°ê²½) íŒŒì¼ ì¶”ì¶œ ë¡œì§ì€ ì™„ì „íˆ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.

    # 4. ìµœì¢… ë°ì´í„°ì…‹ ë¶„í•  (8:2)
    random.shuffle(final_replicated_list)
    
    num_total = len(final_replicated_list)
    num_train = int(num_total * train_ratio)
    
    train_replicated = final_replicated_list[:num_train]
    valid_replicated = final_replicated_list[num_train:]

    print(f"\n--- ìµœì¢… Train/Valid ë¶„í•  (ì´ {num_total}ê°œ íŒŒì¼) ---")
    print(f"Train ì…‹ (ë³µì œ): {len(train_replicated)}ê°œ íŒŒì¼ ({train_ratio*100:.0f}%)")
    print(f"Valid ì…‹ (ë³µì œ): {len(valid_replicated)}ê°œ íŒŒì¼ ({(1-train_ratio)*100:.0f}%)")

    # 5. íŒŒì¼ ë³µì‚¬ ë° ë°ì´í„°ì…‹ ìƒì„±
    train_output_dir = final_root / "train"
    valid_output_dir = final_root / "valid"
    (train_output_dir / "images").mkdir(parents=True, exist_ok=True)
    (train_output_dir / "labels").mkdir(parents=True, exist_ok=True)
    (valid_output_dir / "images").mkdir(parents=True, exist_ok=True)
    (valid_output_dir / "labels").mkdir(parents=True, exist_ok=True)
    
    def replicate_and_copy(replicated_list, target_dir):
        target_img_dir = target_dir / "images"
        target_lbl_dir = target_dir / "labels"
        
        for original_path, new_stem in replicated_list:
            original_stem = original_path.stem
            original_image_path = image_dir / f"{original_stem}.jpg"
            
            if original_image_path.exists() and original_path.exists():
                new_image_name = f"{new_stem}.jpg"
                new_label_name = f"{new_stem}.txt"
                
                shutil.copy(original_image_path, target_img_dir / new_image_name)
                shutil.copy(original_path, target_lbl_dir / new_label_name)
                
    replicate_and_copy(train_replicated, train_output_dir)
    replicate_and_copy(valid_replicated, valid_output_dir)

    print(f"\nâœ… ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ! ì¶œë ¥ ê²½ë¡œ: {final_root}")

    return final_root

# =======================
# [3ë‹¨ê³„] íƒ€ì¼ ë°ì´í„° í•™ìŠµ
# =======================
# =======================
# [3ë‹¨ê³„] íƒ€ì¼ ë°ì´í„° í•™ìŠµ (ì›ë³¸ í•™ìŠµ ë° íŒŒì¸ íŠœë‹ ëª¨ë‘ ì§€ì›)
# =======================
# =======================
# [3ë‹¨ê³„] íƒ€ì¼ ë°ì´í„° í•™ìŠµ (ì›ë³¸ í•™ìŠµ ë° íŒŒì¸ íŠœë‹ ëª¨ë‘ ì§€ì›)
# =======================
def stage3_train_defect_on_tiles(
    data_yaml_tiles: Path, 
    out_dir: Path,             # out_dir: ìµœì¢… ì €ì¥í•  í´ë” (ì˜ˆ: models/step3 ë˜ëŠ” models/step3/fine)
    weights_path: Path = None, # ì´ˆê¸° ê°€ì¤‘ì¹˜ ê²½ë¡œ
    train_cfg: dict = None      # í•™ìŠµ ì„¤ì • ë®ì–´ì“°ê¸°
) -> Path: 
    print("\n=== [3ë‹¨ê³„] íƒ€ì¼ ë°ì´í„°ë¡œ ê²°í•¨ ëª¨ë¸ í•™ìŠµ ===")
    
    # 1. ëª¨ë¸ ì´ˆê¸°í™”
    if weights_path and weights_path.exists():
        print(f"â­ íŒŒì¸ íŠœë‹ ì‹œì‘: ì´ˆê¸° ê°€ì¤‘ì¹˜ ê²½ë¡œ: {weights_path}")
        model = YOLO(str(weights_path)) 
    else:
        print(f"â­ ì´ˆê¸° í•™ìŠµ ì‹œì‘: ëª¨ë¸ ì„¤ì • íŒŒì¼ ì‚¬ìš©: {MODEL_CFG}")
        model = YOLO(MODEL_CFG)
    
    # 2. ìµœì¢… í•™ìŠµ ì„¤ì • ì¤€ë¹„
    if train_cfg:
        final_train_cfg = TRAIN_CFG.copy()
        final_train_cfg.update(train_cfg)
        print(f"   - ì„¤ì • ë®ì–´ì“°ê¸° ì ìš©: {list(train_cfg.keys())}")
    else:
        final_train_cfg = TRAIN_CFG 
        print("   - ê¸°ë³¸ TRAIN_CFG ì„¤ì • ì‚¬ìš©")
        
    # 3. í•™ìŠµ ì¸ì ì¡°í•© ë° ì‹¤í–‰
    train_args = {
        "data": str(data_yaml_tiles),
        "project": str(out_dir.parent), # ğŸ‘ˆ **ìˆ˜ì •**: out_dirì˜ ë¶€ëª¨ í´ë”ë¥¼ projectë¡œ ì§€ì •
        "name": out_dir.name,          # ğŸ‘ˆ **ìˆ˜ì •**: out_dirì˜ ë§ˆì§€ë§‰ ì´ë¦„ì„ nameìœ¼ë¡œ ì§€ì •
        "device": device_str(),
        **final_train_cfg,
        "plots": True,
        "exist_ok": True,
    }
    
    # 4. í•™ìŠµ ì‹œì‘
    results = model.train(**train_args)
    
    # 5. ê²°ê³¼ ë°˜í™˜
    # YOLOv8ì´ project/nameìœ¼ë¡œ ì €ì¥í•˜ë¯€ë¡œ, out_dir ê²½ë¡œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìµœì¢… ê²½ë¡œë¥¼ ê³„ì‚°
    best = Path(results.save_dir) / "weights" / "best.pt"
    print(f"[3ë‹¨ê³„ ì™„ë£Œ] best weights: {best}")
    return best


# =======================
# [4ë‹¨ê³„] SAHI ì¶”ë¡  (íƒ€ì¼ ê·œì¹™ ë™ì¼)
# =======================
def _measure_text(draw, text: str, font=None):
    # Pillow >= 8.0
    if hasattr(draw, "textbbox"):
        l, t, r, b = draw.textbbox((0, 0), text, font=font)
        return r - l, b - t
    # Fallbacks
    if font is not None and hasattr(font, "getbbox"):
        l, t, r, b = font.getbbox(text)
        return r - l, b - t
    if font is not None and hasattr(font, "getsize"):
        return font.getsize(text)
    # ì•„ì£¼ ë³´ìˆ˜ì ì¸ ìµœí›„ì˜ ì¶”ì •
    return (max(1, int(0.6 * 12 * len(text))), 12)

from PIL import Image, ImageDraw, ImageFont
from sahi import AutoDetectionModel
from sahi.predict import get_sliced_prediction

def stage4_infer_yolo_with_sahi(
    weights_path: Path,
    cropped_test_split: Path,
    out_dir: Path,
    sahi_cfg: dict,
    keep_empty: bool = True,
    save_vis: bool = True,
):
    """
    í…ŒìŠ¤íŠ¸(í¬ë¡­ íœ ) ì´ë¯¸ì§€ë¥¼ SAHI ìŠ¬ë¼ì´ì‹±ìœ¼ë¡œ ì¶”ë¡ í•˜ê³ ,
    ê²°ê³¼ë¥¼ YOLO í¬ë§·(txt, 'cls cx cy w h conf')ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    - ìŠ¬ë¼ì´ì‹± ê·œì¹™: sahi_cfg (í›ˆë ¨ê³¼ ë™ì¼)
    - postprocess: sahi_cfg (NMS/IOU/threshold ë“±)
    """
    lbl_dir = out_dir / "labels"
    vis_dir = out_dir / "images_vis"
    ensure_dir(lbl_dir)
    if save_vis:
        ensure_dir(vis_dir)

    print("\n=== [4ë‹¨ê³„] SAHI ì¶”ë¡  (YOLO í¬ë§· ì €ì¥) ===")
    dmodel = AutoDetectionModel.from_pretrained(
        model_type="ultralytics",
        model_path=str(weights_path),
        confidence_threshold=sahi_cfg.get("conf_thres", 0.5),
        device=device_str(),
    )

    imgs = list_images(cropped_test_split / "images")
    if not imgs:
        raise FileNotFoundError(f"í¬ë¡­ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {cropped_test_split/'images'}")

    # í°íŠ¸ëŠ” ì„ íƒ(ì—†ëŠ” í™˜ê²½ ê³ ë ¤)
    try:
        font = ImageFont.truetype("DejaVuSans.ttf", 14)
    except Exception:
        font = None

    for ip in imgs:
        im = Image.open(ip).convert("RGB")
        W, H = im.size
        slice_h, slice_w, ovh, ovw = compute_slice_params(W, H, sahi_cfg)

        # SAHI ìŠ¬ë¼ì´ìŠ¤ ì¶”ë¡  (+ ë³‘í•© í›„ì²˜ë¦¬)
        res = get_sliced_prediction(
            image=im,
            detection_model=dmodel,
            slice_height=slice_h,
            slice_width=slice_w,
            overlap_height_ratio=ovh,
            overlap_width_ratio=ovw,
            postprocess_type=sahi_cfg.get("postprocess", "NMS"),
            postprocess_match_metric=sahi_cfg.get("match_metric", "IOU"),
            postprocess_match_threshold=sahi_cfg.get("match_thres", 0.45),
            postprocess_class_agnostic=True,
        )

        # ğŸ”¥ confidence filtering ì¶”ê°€
       
        stem = Path(ip).stem
        yolo_lines = []

        # SAHIëŠ” ì¤‘ë³µì„ ë³‘í•©í•œ object_prediction_listë¥¼ ì œê³µ
        for op in res.object_prediction_list:
            # bbox: VOC(xmin, ymin, xmax, ymax)
            x1, y1, x2, y2 = map(float, op.bbox.to_voc_bbox())
            # YOLO ì •ê·œí™”(cx, cy, w, h)
            bw = max(1e-6, x2 - x1)
            bh = max(1e-6, y2 - y1)
            cx = (x1 + x2) / 2.0
            cy = (y1 + y2) / 2.0

            cxn = min(max(cx / W, 0.0), 1.0)
            cyn = min(max(cy / H, 0.0), 1.0)
            bwn = min(max(bw / W, 1e-6), 1.0)
            bhn = min(max(bh / H, 1e-6), 1.0)

            # í´ë˜ìŠ¤/ì ìˆ˜
            cls_id = getattr(op.category, "id", 0)
            try:
                cls_id = int(cls_id)
            except Exception:
                cls_id = 0
            score = getattr(op.score, "value", None)
            conf = 0.0 if score is None else float(score)

            yolo_lines.append(f"{cls_id} {cxn:.6f} {cyn:.6f} {bwn:.6f} {bhn:.6f} {conf:.4f}")

        # ì‹ ë¢°ë„ ë†’ì€ ìˆœ ì •ë ¬(ì„ íƒ ì‚¬í•­)
        if yolo_lines:
            yolo_lines = sorted(
                yolo_lines,
                key=lambda s: float(s.strip().split()[-1]),
                reverse=True,
            )

        # YOLO ë¼ë²¨ ì €ì¥
        out_txt = lbl_dir / f"{stem}.txt"
        if yolo_lines or keep_empty:
            with open(out_txt, "w") as f:
                f.write("\n".join(yolo_lines))
        else:
            # keep_empty=False ì´ê³  ì˜ˆì¸¡ ì—†ìœ¼ë©´ íŒŒì¼ ë¯¸ìƒì„±
            pass

        # ê°„ë‹¨ ì‹œê°í™”(ì„ íƒ)
        if save_vis:
            try:
                vis = im.copy()
                draw = ImageDraw.Draw(vis)
                for op in res.object_prediction_list:
                    x1, y1, x2, y2 = map(int, op.bbox.to_voc_bbox())
                    draw.rectangle([(x1, y1), (x2, y2)], outline=(255, 0, 0), width=2)

                    cls_name = getattr(op.category, "name", None)
                    cls_id = getattr(op.category, "id", None)
                    label = str(cls_name if cls_name is not None else cls_id)
                    score = getattr(op.score, "value", None)
                    if score is not None:
                        label = f"{label}:{score:.2f}"

                    if label:
                        tw, th = _measure_text(draw, label, font=font)
                        tx, ty = x1, max(0, y1 - th - 2)
                        # í…ìŠ¤íŠ¸ ë°°ê²½ ë°•ìŠ¤
                        draw.rectangle([(tx, ty), (tx + tw + 2, ty + th + 2)], fill=(255, 0, 0))
                        draw.text((tx + 1, ty + 1), label, fill=(255, 255, 255), font=font)

                vis.save((vis_dir / f"{stem}.png"))
            except Exception as e:
                print(f"âš ï¸ {ip.name} ì‹œê°í™” ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

    print(f"[4ë‹¨ê³„ ì™„ë£Œ] YOLO labels: {lbl_dir}")
    if save_vis:
        print(f"[4ë‹¨ê³„ ì™„ë£Œ] ì‹œê°í™”: {vis_dir}")


def fine_tuning_placeholder():
    FT_TRAIN_CFG = TRAIN_CFG.copy() 
    
    FT_TRAIN_CFG.update(dict(
        box=4.0,     
        cls=0.3,     
        lr0=0.0005,

        epochs=100,
    ))

    PREV_BEST_WEIGHTS = MODELS_ROOT / "step3" / "fine" / "weights" / "best.pt" 
    STAGE3_FT_DIR = STAGE3_DIR / "fine2" 
    
    best_defect_ft = stage3_train_defect_on_tiles(
        data_yaml_tiles=DATA_YAML_TILES, 
        out_dir=STAGE3_FT_DIR,           
        weights_path=PREV_BEST_WEIGHTS,
        train_cfg=FT_TRAIN_CFG 
    )
    return best_defect_ft

# =======================
# main
# =======================
def main():
    # 1ë‹¨ê³„ (ì˜µì…˜): ì´ë¯¸ ì›ë³¸ í•™ìŠµ ëë‚¬ìœ¼ë©´ ìƒëµ
    # best_wheel = stage1_train_p2(DATA_YAML, STAGE1_DIR)

    # 2ë‹¨ê³„: SAHI íƒ€ì¼ ë¶„í•  (size/count_v ëª¨ë“œ ì¤‘ íƒ1)
    #stage2_tile_all_with_sahi()
    
    # 2.5ë‹¨ê³„ : ë°ì´í„° ì˜¤ë²„ìƒ˜í”Œë§
    #final_output_path = create_iterative_splits(tile_root=TILE_ROOT)
    #print(f"\nâœ¨ ìµœì¢… Train/Valid ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ ìœ„ì¹˜: {final_output_path}")
    
    # 2.6ë‹¨ê³„ : ë°ì´í„° ì˜¤ë²„ìƒ˜í”Œë§ - ê²°í•¨ë°ì´í„°ë§Œ
    #final_output_path = oversample_tiles_for_2_loops(tile_root=TILE_ROOT)
    #print(f"\nâœ¨ ìµœì¢… Train/Valid ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ ìœ„ì¹˜: {final_output_path}")


    # 3ë‹¨ê³„: íƒ€ì¼ í•™ìŠµ
    #best_defect = stage3_train_defect_on_tiles(DATA_YAML_TILES, STAGE3_DIR)
    #best_defect = MODELS_ROOT / "step3" / "weights" / "best.pt"  
    # 4ë‹¨ê³„: SAHI ì¶”ë¡  (2ë‹¨ê³„ì™€ ë™ì¼ ê·œì¹™)
    #stage4_infer_yolo_with_sahi(weights_path=best_defect, cropped_test_split=CROP_TEST, out_dir=STAGE4_DIR, sahi_cfg=SAHI_CFG, keep_empty=True, save_vis=True)

    # 5ë‹¨ê³„ íŒŒì¸íŠœë‹
    best_defect_ft = fine_tuning_placeholder()
    print(f"\nâœ¨ íŒŒì¸íŠœë‹ ì™„ë£Œëœ ìµœì¢… ëª¨ë¸: {best_defect_ft}")

if __name__ == "__main__":
    main()
