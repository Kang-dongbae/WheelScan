from pathlib import Path
from typing import Dict, Optional
from ultralytics import YOLO

# ë‚´ë¶€ ëª¨ë“ˆ ì„í¬íŠ¸
from utils import device_str
import config as cfg

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, models, transforms
from torch.utils.data import DataLoader, WeightedRandomSampler
import numpy as np
import os
import time
import copy

# =========================================================
# [ì„¤ì • ì˜ì—­]
# =========================================================
DATA_DIR = r"C:\Dev\WheelScan\data\cls_tiles" # ë°ì´í„° ê²½ë¡œ
MODEL_SAVE_PATH = r"C:\Dev\WheelScan\models\step0\best_classifier.pth"
BATCH_SIZE = 32
EPOCHS = 20
LEARNING_RATE = 0.0001
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# =========================================================
# [ë°ì´í„°ì…‹ ì¤€ë¹„]
# =========================================================
def get_data_loaders():
    # 1. ì´ë¯¸ì§€ ë³€í™˜ (Augmentation)
    # Trainì—ëŠ” ë‹¤ì–‘ì„±ì„ ì£¼ê¸° ìœ„í•´ ë³€í˜•ì„ ê°€í•¨
    train_transforms = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(), # ì¢Œìš° ë°˜ì „
        transforms.RandomVerticalFlip(),   # ìƒí•˜ ë°˜ì „ (ì°¨ë¥œì€ íšŒì „ì²´ë¼ ìœ íš¨)
        transforms.RandomRotation(15),     # ì•½ê°„ì˜ íšŒì „
        transforms.ColorJitter(brightness=0.1, contrast=0.1), # ì¡°ëª… ë³€í™” ëŒ€ì‘
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    # ValidëŠ” ì›ë³¸ ê·¸ëŒ€ë¡œ (Resizeë§Œ)
    val_transforms = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    # 2. ë°ì´í„°ì…‹ ë¡œë“œ
    train_dataset = datasets.ImageFolder(os.path.join(DATA_DIR, 'train'), train_transforms)
    val_dataset = datasets.ImageFolder(os.path.join(DATA_DIR, 'valid'), val_transforms)

    # í´ë˜ìŠ¤ ë§¤í•‘ í™•ì¸ (ì•ŒíŒŒë²³ ìˆœì„œ: defect=0, normal=1 ì¼ ê°€ëŠ¥ì„± ë†’ìŒ)
    print(f"Class Mapping: {train_dataset.class_to_idx}")
    
    # 3. [í•µì‹¬] ë¶ˆê· í˜• í•´ê²°: WeightedRandomSampler
    # ê° í´ë˜ìŠ¤ì˜ ìƒ˜í”Œ ê°œìˆ˜ í™•ì¸
    targets = train_dataset.targets
    class_counts = np.bincount(targets)
    
    print(f"Train Data Counts: {class_counts}") 
    # ì˜ˆ: [1485, 2227] -> ì ì€ ìª½ ê°€ì¤‘ì¹˜ë¥¼ ë†’ì„
    
    class_weights = 1. / class_counts
    sample_weights = [class_weights[t] for t in targets]
    
    # ìƒ˜í”ŒëŸ¬ ìƒì„±
    sampler = WeightedRandomSampler(sample_weights, len(sample_weights))

    # 4. ë¡œë” ìƒì„±
    # train_loaderì—ëŠ” samplerë¥¼ ì ìš© (shuffle=Trueì™€ í•¨ê»˜ ì“°ë©´ ì•ˆë¨)
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler, num_workers=0)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)

    return train_loader, val_loader, train_dataset.class_to_idx


# =======================
# [0ë‹¨ê³„] (ì˜µì…˜) ì›ë³¸ í•™ìŠµ
# =======================
def stage0_cls_train():
    print(f"Using device: {DEVICE}")
    
    train_loader, val_loader, class_idx = get_data_loaders()
    
    # Defectê°€ ì–´ë–¤ ì¸ë±ìŠ¤ì¸ì§€ í™•ì¸ (ë³´í†µ 0 ì•„ë‹ˆë©´ 1)
    defect_idx = class_idx['defect']
    
    # ëª¨ë¸ ì •ì˜ (ResNet18 - ê°€ë³ê³  ì„±ëŠ¥ ì¢‹ìŒ)
    model = models.resnet18(weights='IMAGENET1K_V1')
    num_ftrs = model.fc.in_features
    model.fc = nn.Linear(num_ftrs, 2) # 2ì§„ ë¶„ë¥˜
    model = model.to(DEVICE)

    class_weights = torch.tensor([1.0, 1.0]).to(DEVICE)
    class_weights[defect_idx] = 3.0 
    
    print(f"Applying Class Weights: {class_weights}") # í™•ì¸ìš© ì¶œë ¥
    
    # ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ CrossEntropyLoss ì‚¬ìš©
    criterion = nn.CrossEntropyLoss(weight=class_weights)
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

    best_recall = 0.0
    best_model_wts = copy.deepcopy(model.state_dict())

    for epoch in range(EPOCHS):
        # --- Train Phase ---
        model.train()
        running_loss = 0.0
        
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * inputs.size(0)

        epoch_loss = running_loss / len(train_loader.dataset)

        # --- Valid Phase ---
        model.eval()
        val_loss = 0.0
        
        # ë©”íŠ¸ë¦­ ê³„ì‚° ë³€ìˆ˜
        tp = 0 # True Positive (ê²°í•¨ì„ ê²°í•¨ì´ë¼ ë§ì¶¤)
        fn = 0 # False Negative (ê²°í•¨ì„ ì •ìƒì´ë¼ ë†“ì¹¨ - ì¹˜ëª…ì )
        fp = 0 # False Positive (ì •ìƒì„ ê²°í•¨ì´ë¼ ì˜¤í•´ - ê´œì°®ìŒ)
        tn = 0 # True Negative (ì •ìƒì„ ì •ìƒì´ë¼ ë§ì¶¤)

        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
                
                _, preds = torch.max(outputs, 1)

                # ê²°í•¨(defect_idx)ì„ Positiveë¡œ ê°„ì£¼í•˜ê³  ê³„ì‚°
                for p, l in zip(preds, labels):
                    if l == defect_idx: # ì‹¤ì œ ê²°í•¨ì¸ ê²½ìš°
                        if p == defect_idx: tp += 1
                        else: fn += 1
                    else: # ì‹¤ì œ ì •ìƒì¸ ê²½ìš°
                        if p == defect_idx: fp += 1
                        else: tn += 1

        val_loss = val_loss / len(val_loader.dataset)
        
        # ì§€í‘œ ê³„ì‚°
        accuracy = (tp + tn) / (tp + tn + fp + fn + 1e-10)
        recall = tp / (tp + fn + 1e-10)       # ì¬í˜„ìœ¨ (ì¤‘ìš”)
        precision = tp / (tp + fp + 1e-10)    # ì •ë°€ë„
        
        print(f"Epoch {epoch+1}/{EPOCHS}")
        print(f"Train Loss: {epoch_loss:.4f} | Val Loss: {val_loss:.4f}")
        print(f"Val Acc: {accuracy:.4f} | Precision: {precision:.4f}")
        print(f"â˜… Defect Recall: {recall:.4f} (TP:{tp}, FN:{fn})") 
        print("-" * 30)

        # ëª¨ë¸ ì €ì¥ ê¸°ì¤€: Recallì´ ê°€ì¥ ë†’ì„ ë•Œ ì €ì¥ (ë†“ì¹˜ë©´ ì•ˆë˜ë‹ˆê¹Œ)
        # ë§Œì•½ Recallì´ ê°™ë‹¤ë©´ Accuracyê°€ ë†’ì€ ìˆœ
        if recall > best_recall:
            best_recall = recall
            best_model_wts = copy.deepcopy(model.state_dict())
            torch.save(model.state_dict(), MODEL_SAVE_PATH)
            print(">> Best Model Saved (Recall Updated)")

    print(f"Training Complete. Best Recall: {best_recall:.4f}")
    return best_model_wts


# =======================
# [1ë‹¨ê³„] (ì˜µì…˜) ì›ë³¸ í•™ìŠµ
# =======================
def stage1_train_p2(
    data_yaml: Path = cfg.DATA_YAML, 
    out_dir: Path = cfg.STAGE1_DIR
) -> Path:
    print("\n=== [1ë‹¨ê³„] í•™ìŠµ ì‹œì‘ (yolo11m-p2) ===")
    print(f"data: {data_yaml}")
    print(f"model cfg: {cfg.MODEL_CFG}")

    model = YOLO(cfg.MODEL_CFG)
    train_args = {
        "data": str(data_yaml),
        "project": str(cfg.MODELS_ROOT),
        "name": out_dir.name,
        "device": device_str(),
        **cfg.TRAIN_CFG,
        "exist_ok": True,
    }
    results = model.train(**train_args)
    best = Path(results.save_dir) / "weights" / "best.pt"
    print(f"[1ë‹¨ê³„ ì™„ë£Œ] best weights: {best}")
    return best

import torch
import torch.nn.functional as F
from ultralytics.utils.loss import v8DetectionLoss
import time

def focal_bce_with_gamma(logits, targets, gamma: float = 2.0):
    bce = F.binary_cross_entropy_with_logits(logits, targets, reduction="none")
    pt = torch.exp(-bce)
    return ((1 - pt) ** gamma * bce).mean()

def focal_bce_gamma2(logits, targets):
    return focal_bce_with_gamma(logits, targets, gamma=2.0)

def patch_v8_focal_bce_gamma2():
    """pickle-safe focal patch + initì—ì„œ 1íšŒ ê²€ì¦ ë¡œê·¸"""
    orig_init = v8DetectionLoss.__init__

    def new_init(self, model):
        orig_init(self, model)
        self.bce = focal_bce_gamma2
        if hasattr(self, "BCEcls"):
            self.BCEcls = focal_bce_gamma2
        if hasattr(self, "BCEobj"):
            self.BCEobj = focal_bce_gamma2
        # âœ… ì—¬ê¸°ì„œ ë°”ë¡œ â€˜ì ìš© í™•ì¸â€™ ë¡œê·¸ 1íšŒ ì¶œë ¥
        print("[FOCAL] v8DetectionLoss constructed â†’ bce:", self.bce is focal_bce_gamma2,
              "/ has BCEcls:", hasattr(self, "BCEcls"),
              "/ has BCEobj:", hasattr(self, "BCEobj"))

    v8DetectionLoss.__init__ = new_init
    print("âœ… Patched: v8DetectionLoss now uses Focal BCE (Î³ = 2.0) [pickle-safe]")



# =======================
# [3ë‹¨ê³„] íƒ€ì¼ ë°ì´í„° í•™ìŠµ (ì›ë³¸ í•™ìŠµ ì„ ë° íŒŒì¸ íŠœë‹ ëª¨ë‘ ì§€ì›)
# =======================
def stage3_train_defect_on_tiles(
    data_yaml_tiles: Path, 
    out_dir: Path,             
    weights_path: Optional[Path] = None, 
    train_cfg_override: Optional[Dict] = None
) -> Path: 
    print("\n=== [3ë‹¨ê³„] íƒ€ì¼ ë°ì´í„°ë¡œ ê²°í•¨ ëª¨ë¸ í•™ìŠµ ===")
    
    # 1ï¸âƒ£ ëª¨ë¸ ì´ˆê¸°í™”
    if weights_path and weights_path.exists():
        print(f"íŒŒì¸ íŠœë‹ ì‹œì‘: ì´ˆê¸° ê°€ì¤‘ì¹˜ ê²½ë¡œ: {weights_path}")
        model = YOLO(str(weights_path)) 
    else:
        print(f"ì´ˆê¸° í•™ìŠµ ì‹œì‘: ëª¨ë¸ ì„¤ì • íŒŒì¼ ì‚¬ìš©: {cfg.MODEL_CFG}")
        model = YOLO(cfg.MODEL_CFG)
    
    #patch_v8_focal_bce_gamma2()

    # 2ï¸âƒ£ í•™ìŠµ ì„¤ì • ë³‘í•©
    final_train_cfg = cfg.TRAIN_CFG.copy()
    if train_cfg_override:
        final_train_cfg.update(train_cfg_override)
        print(f"ì„¤ì • ë®ì–´ì“°ê¸° ì ìš©: {list(train_cfg_override.keys())}")
    else:
        print("ê¸°ë³¸ TRAIN_CFG ì„¤ì • ì‚¬ìš©")
        
    # 3ï¸âƒ£ í•™ìŠµ ì¸ì ì¡°í•©
    train_args = {
        "data": str(data_yaml_tiles),
        "project": str(out_dir.parent), 
        "name": out_dir.name,         
        "device": device_str(),
        **final_train_cfg,
        "plots": True,
        "exist_ok": True,
    }
    
    # 4ï¸âƒ£ í•™ìŠµ ì‹œì‘
    results = model.train(**train_args)
    
    # 5ï¸âƒ£ í•™ìŠµ ê²°ê³¼ ì €ì¥
    save_dir = Path(results.save_dir) 
    val_results = model.val(data=str(data_yaml_tiles), split='val')
    val_results.save_dir = save_dir 
    
    try:
        val_results.save_metrics(save_dir / "val_results.csv")
        print(f"âœ… Validation ê²°ê³¼: {save_dir / 'val_results.csv'}")
    except Exception as e:
        print(f"âš ï¸ Validation ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")

    best = Path(results.save_dir) / "weights" / "best.pt"
    print(f"[3ë‹¨ê³„ ì™„ë£Œ] best weights: {best}")
    return best

# =======================
# [3.5ë‹¨ê³„] íŒŒì¸íŠœë‹ ì‹¤í–‰ê¸°
# =======================
def run_fine_tuning() -> Path:

    print("\n=== [3.5ë‹¨ê³„] íŒŒì¸íŠœë‹ ì‹œì‘ ===")
    
    best_defect_ft = stage3_train_defect_on_tiles(
        data_yaml_tiles=cfg.DATA_YAML_TILES, 
        out_dir=cfg.STAGE3_FT_DIR,           
        weights_path=cfg.PREV_BEST_WEIGHTS_FOR_FT,
        train_cfg_override=cfg.FT_TRAIN_CFG 
    )
    return best_defect_ft

# =======================
# [0.5ë‹¨ê³„] conf* ê³ ì • í‰ê°€ ë° ë¡œê·¸ ëˆ„ì 
# =======================
from ultralytics import YOLO
from pathlib import Path
import csv, time

def evaluate_fixed_conf(
    model_path,
    data_yaml,
    conf_star: float,
    iou_thr: float = 0.55,
    stage_name: str = "Stage",
    log_csv: str = "C:/Dev/WheelScan/models/step3/fix_conf/stagewise_results.csv"
):
    """
    conf* (ìš´ì˜ì ) ê³ ì •ìœ¼ë¡œ YOLO validationì„ ìˆ˜í–‰í•˜ê³ , ê²°ê³¼ë¥¼ CSV ë¡œê·¸ì— ëˆ„ì  ê¸°ë¡.
    - model_path : YOLO weight (best.pt)
    - data_yaml  : dataset yaml ê²½ë¡œ
    - conf_star  : Stage0.5ì—ì„œ êµ¬í•œ ìš´ì˜ì 
    - iou_thr    : IoU threshold (í†µì¼)
    - stage_name : Stage ì´ë¦„ (ex. Stage1_Augment)
    - log_csv    : ê²°ê³¼ ëˆ„ì  CSV ê²½ë¡œ
    """

    model = YOLO(str(model_path))
    print(f"\n[{stage_name}] Validation @ conf={conf_star:.3f}, IoU={iou_thr:.2f}")
    results = model.val(
        data=str(data_yaml),
        split="val",
        conf=conf_star,
        iou=iou_thr,
        save_txt=False
    )

    P, R, mAP50, mAP5095 = (
        float(results.box.mp),
        float(results.box.mr),
        float(results.box.map50),
        float(results.box.map)
    )

    print(f"âœ… {stage_name} ê²°ê³¼:")
    print(f"   Precision={P:.4f}, Recall={R:.4f}, mAP50={mAP50:.4f}, mAP50-95={mAP5095:.4f}")

    # ë¡œê·¸ ì €ì¥
    log_path = Path(log_csv)
    row = {
        "time": time.strftime("%Y-%m-%d %H:%M:%S"),
        "stage": stage_name,
        "conf_star": conf_star,
        "precision": P,
        "recall": R,
        "mAP50": mAP50,
        "mAP50-95": mAP5095,
        "model_path": str(model_path)
    }
    write_header = not log_path.exists()
    with open(log_path, "a", newline="", encoding="utf-8") as f:
        w = csv.DictWriter(f, fieldnames=row.keys())
        if write_header:
            w.writeheader()
        w.writerow(row)
    print(f"ğŸ“„ ë¡œê·¸ ì €ì¥ ì™„ë£Œ: {log_path}")

    return results